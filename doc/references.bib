
@incollection{lewis_usability_2006,
	title = {Usability Testing},
	abstract = {Usability testing is an essential skill for usability practitioners -- professionals whose primary goal is to provide guidance to product developers for the purpose of improving the ease of use of their products. It is by no means the only skill with which usability practitioners must have proficiency, but it is an important one. Surveys of experienced usability practitioners have indicated that usability testing is a very frequently used method, second only to the use of iterative design. 

One goal of this chapter is to provide an introduction to the practice of usability testing. This includes some discussion of the concept of usability and the history of usability testing, various goals of usability testing, and running usability tests. A second goal is to cover more advanced topics, such as sample size estimation for usability tests, computation of confidence intervals, and the use of standardized usability questionnaires.},
	pages = {1275--1316},
	booktitle = {Handbook of Human Factors and Ergonomics},
	author = {Lewis, James},
	date = {2006-02-28},
	doi = {10.1002/0470048204.ch49},
	note = {Journal Abbreviation: Handbook of Human Factors and Ergonomics},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\5XG9II7U\\Lewis - 2006 - Usability Testing.pdf:application/pdf},
}

@article{maxwell_developing_2021,
	title = {Developing Contemporary Web-Based Interaction Logging Infrastructure: The Design and Challenges of {LogUI}},
	abstract = {Studies involving user interfaces typically involve the capturing and recording (logging) of key user interactions between the user and the system being examined. However, anecdotal evidence suggests that researchers often implement their own logging infrastructure—sometimes in a piecemeal fashion—which can lead to numerous implementation mistakes (due to misunderstanding or ignoring differences between web browsers, for example). While efforts have been made to develop interaction logging solutions for experimentation and commercial use, many solutions either use obsolete technology, are prohibitively expensive, are complex to use (and require extensive programming knowledge), or have no source code available. To address these issues, we have developed {LogUI}, an easy-to-use yet powerful interaction logging framework that can capture virtually any user interaction within a web-based environment. {LogUI} has been successfully used in several user studies since its launch. This paper provides an in-depth discussion into how we have designed {LogUI}, and provides narrative on the key challenges that we are looking to address moving forward.},
	pages = {11},
	author = {Maxwell, David and Hauff, Claudia},
	date = {2021},
	langid = {english},
	file = {Maxwell and Hauff - Developing Contemporary Web-Based Interaction Logg.pdf:C\:\\Users\\vimio\\Zotero\\storage\\KLWLCZAS\\Maxwell and Hauff - Developing Contemporary Web-Based Interaction Logg.pdf:application/pdf},
}

@inproceedings{scells_big_2021,
	location = {Virtual Event Canada},
	title = {\textit{Big Brother:} A Drop-In Website Interaction Logging Service},
	isbn = {978-1-4503-8037-9},
	url = {https://dl.acm.org/doi/10.1145/3404835.3462781},
	doi = {10.1145/3404835.3462781},
	shorttitle = {{\textless}i{\textgreater}Big Brother},
	abstract = {Fine-grained logging of interactions in user studies is important for studying user behaviour, among other reasons. However, in many research scenarios, the way interactions are logged is usually tied to a monolithic system. We present a generic, application-independent service for logging interactions in web-pages, specifically targetting user studies. Our service, Big Brother, can be dropped-in to existing user interfaces with almost no configuration required by researchers. Big Brother has already been used in several user studies to record interactions in a number of user study research scenarios, such as lab-based and crowdsourcing environments. We further demonstrate the ability for Big Brother to scale to very large user studies through benchmarking experiments. Big Brother also provides a number of additional tools for visualising and analysing interactions. Big Brother significantly lowers the barrier to entry for logging user interactions by providing a minimal but powerful, no configuration necessary, service for researchers and practitioners of user studies that can scale to thousands of concurrent sessions. We have made the source code and releases for Big Brother available for download at https://github.com/hscells/bigbro.},
	eventtitle = {{SIGIR} '21: The 44th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	pages = {2590--2594},
	booktitle = {Proceedings of the 44th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Scells, Harrisen and {Jimmy} and Zuccon, Guido},
	urldate = {2022-06-07},
	date = {2021-07-11},
	langid = {english},
	file = {Scells et al. - 2021 - Big Brother A Drop-In Website Interaction .pdf:C\:\\Users\\vimio\\Zotero\\storage\\JJE3R7LF\\Scells et al. - 2021 - Big Brother A Drop-In Website Interaction .pdf:application/pdf},
}

@article{sandom_human_2004,
	title = {Human Factors for Engineers},
	pages = {389},
	journaltitle = {Human Factors},
	author = {Sandom, Carl and Harvey, Roger S},
	date = {2004},
	langid = {english},
	file = {Sandom and Harvey - Human Factors for Engineers.pdf:C\:\\Users\\vimio\\Zotero\\storage\\2B4X4DWZ\\Sandom and Harvey - Human Factors for Engineers.pdf:application/pdf},
}

@article{westerman_investigating_1996,
	title = {Investigating the human-computer interface using the Datalogger},
	volume = {28},
	issn = {1532-5970},
	url = {https://doi.org/10.3758/BF03200549},
	doi = {10.3758/BF03200549},
	abstract = {Methods of gathering user input data for investigations into human-computer interaction are considered. These include the use of human monitors, “instrumentation” of computer programs, and the use of “background” keylogging software. The Datalogger is presented as an example of the latter method, which provides a time-stamped record of keypresses and mouse movement and allows the outcomes of user actions to be replayed.},
	pages = {603--606},
	number = {4},
	journaltitle = {Behavior Research Methods, Instruments \& Computers},
	shortjournal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Westerman, S. J. and Hambly, S. and Alder, C. and Wyatt-Millington, C. W. and Shryane, N. M. and Crawshaw, C. M. and Hockey, G. R. J.},
	urldate = {2022-06-07},
	date = {1996-12-01},
	langid = {english},
	keywords = {Behavior Research Method, Exploratory Sequential Data Analysis, Human Factor Society, Mouse Movement, User Input Data},
}

@article{westerman_investigating_1996-1,
	title = {Investigating the human-computer interface using the Datalogger},
	volume = {28},
	doi = {10.3758/BF03200549},
	abstract = {Methods of gathering user input data for investigations into human-computer interaction are considered. These include the
use of human monitors, “instrumentation” of computer programs, and the use of “background” keylogging software. The Datalogger
is presented as an example of the latter method, which provides a time-stamped record of keypresses and mouse movement and
allows the outcomes of user actions to be replayed.},
	pages = {603--606},
	journaltitle = {Behavior Research Methods, Instruments, \& Computers},
	shortjournal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Westerman, S. and Hambly, S. and Alder, C. and Wyatt-Millington, C. and Shryane, Nick and Crawshaw, C. and Hockey, Glyn},
	date = {1996-12-01},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\26WUU8GK\\Westerman et al. - 1996 - Investigating the human-computer interface using t.pdf:application/pdf},
}

@article{gerken_how_2008,
	title = {How to use interaction logs effectively for usability evaluation},
	abstract = {In this paper we argue for a combined approach of logging analysis and interview techniques to evaluate the usability of web distributed applications. Logging analysis has proven as an efficient and effective method to investigate websites usability. However it seems insufficient for more complex applications. We outline a case study of a library search system, in which users’ information seeking behavior is investigated with both the analysis of log files and qualitative interviews with real users. We argue that such an approach should provide a more accurate usability assessment of the system, especially when users’ performance in a long-run is investigated.},
	pages = {3},
	author = {Gerken, Jens and Bak, Peter and Jetter, Hans-Christian and Klinkhammer, Daniel and Reiterer, Harald},
	date = {2008},
	langid = {english},
	file = {Gerken et al. - How to use interaction logs effectively for usabil.pdf:C\:\\Users\\vimio\\Zotero\\storage\\2CW887GN\\Gerken et al. - How to use interaction logs effectively for usabil.pdf:application/pdf},
}

@inproceedings{lettner_automated_2012,
	location = {New York, {NY}, {USA}},
	title = {Automated and unsupervised user interaction logging as basis for usability evaluation of mobile applications},
	isbn = {978-1-4503-1307-0},
	url = {https://doi.org/10.1145/2428955.2428983},
	doi = {10.1145/2428955.2428983},
	series = {{MoMM} '12},
	abstract = {The evaluation of mobile user interfaces can be a tedious task, especially if usability tests under real-world conditions should be performed. In particular, the evaluation of high-fidelity prototypes provides valuable measures about the quality of mobile applications, which helps designers to identify potentials of improvement for the next revision. Due to their costs or missing expert knowledge evaluation techniques such as cognitive walkthroughs or heuristic evaluation are often not used. Additionally, commercial frameworks provide insufficient details on usability as they only address commercial statistics regarding user loyalty, in-app purchases or demographics. In this paper, we present a novel approach and toolkit for automated and unsupervised evaluation of mobile applications that, in contrast to existing frameworks, is able to trace any user interaction during the entire lifecycle of an application. As a major novelty, our toolkit can be added to mobile applications without changing application source code, which makes it flexible and scalable for all types of applications. Also, our toolkit is able to identify and visualize design flaws such as navigational errors or efficiency for mobile applications.},
	pages = {118--127},
	booktitle = {Proceedings of the 10th International Conference on Advances in Mobile Computing \& Multimedia},
	publisher = {Association for Computing Machinery},
	author = {Lettner, Florian and Holzmann, Clemens},
	urldate = {2022-06-07},
	date = {2012-12-03},
	keywords = {mobile interfaces, software toolkit, usability metrics},
}

@article{jeong_gui_2020,
	title = {{GUI} information-based interaction logging and visualization for asynchronous usability testing},
	volume = {151},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417420301147},
	doi = {10.1016/j.eswa.2020.113289},
	abstract = {Asynchronous usability testing is efficient and promising usability testing methodology. However, evaluators are required to dedicate a considerable amount of effort for identifying usability problems in asynchronous testing. Evaluators cannot observe user interactions directly; only the collected data is available to them for identifying the usability problems. To reduce the amount of effort required, this paper presents a framework and tool for interaction visualization. This framework tracing user interactions based on meaningful {GUI} changes. The collected interaction log is visualized in a way that is similar to the visualization of traversed path used in web domains. Using our approach, the evaluator shall be able to understand user behavior more easily. In addition, we designed a black-box-based interaction logging for minimizing the implementation costs. Our tool especially helpful when testing has a large number of interaction data to analyze. To evaluate the proposed framework and tool, user interaction data were collected, and the results were evaluated by mobile application experts. The evaluation results demonstrate that the user interaction data traced by the proposed framework accurately reflect the user interactions and that the visualization results are valid.},
	pages = {113289},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Jeong, {JongWook} and Kim, {NeungHoe} and In, Hoh Peter},
	urldate = {2022-06-07},
	date = {2020-08-01},
	langid = {english},
	keywords = {Asynchronous remote usability testing, Mobile application, Remote usability testing, Usability testing},
}

@article{candido_log-based_2021,
	title = {Log-based software monitoring: a systematic mapping study},
	volume = {7},
	issn = {2376-5992},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8114802/},
	doi = {10.7717/peerj-cs.489},
	shorttitle = {Log-based software monitoring},
	abstract = {Modern software development and operations rely on monitoring to understand how systems behave in production. The data provided by application logs and runtime environment are essential to detect and diagnose undesired behavior and improve system reliability. However, despite the rich ecosystem around industry-ready log solutions, monitoring complex systems and getting insights from log data remains a challenge. Researchers and practitioners have been actively working to address several challenges related to logs, e.g., how to effectively provide better tooling support for logging decisions to developers, how to effectively process and store log data, and how to extract insights from log data. A holistic view of the research effort on logging practices and automated log analysis is key to provide directions and disseminate the state-of-the-art for technology transfer. In this paper, we study 108 papers (72 research track papers, 24 journals, and 12 industry track papers) from different communities (e.g., machine learning, software engineering, and systems) and structure the research field in light of the life-cycle of log data. Our analysis shows that (1) logging is challenging not only in open-source projects but also in industry, (2) machine learning is a promising approach to enable a contextual analysis of source code for log recommendation but further investigation is required to assess the usability of those tools in practice, (3) few studies approached efficient persistence of log data, and (4) there are open opportunities to analyze application logs and to evaluate state-of-the-art log analysis techniques in a {DevOps} context.},
	pages = {e489},
	journaltitle = {{PeerJ} Computer Science},
	shortjournal = {{PeerJ} Comput Sci},
	author = {Cândido, Jeanderson and Aniche, Maurício and van Deursen, Arie},
	urldate = {2022-06-07},
	date = {2021-05-06},
	pmid = {34013028},
	pmcid = {PMC8114802},
	file = {Full Text:C\:\\Users\\vimio\\Zotero\\storage\\4FHUBTKW\\Cândido et al. - 2021 - Log-based software monitoring a systematic mappin.pdf:application/pdf},
}

@incollection{zhai_interactive_2020,
	location = {New York, {NY}, {USA}},
	title = {Interactive Information Retrieval: Models, Algorithms, and Evaluation},
	isbn = {978-1-4503-8016-4},
	url = {https://doi.org/10.1145/3397271.3401424},
	shorttitle = {Interactive Information Retrieval},
	abstract = {Since Information Retrieval ({IR}) is an interactive process in general, it is important to study Interactive Information Retrieval ({IIR}), where we would attempt to model and optimize an entire interactive retrieval process (rather than a single query) with consideration of many different ways a user can potentially interact with a search engine. This tutorial systematically reviews the progress of research in {IIR} with an emphasis on the most recent progress in the development of models, algorithms, and evaluation strategies for {IIR}. It starts with a broad overview of research in {IIR} and then gives an introduction to formal models for {IIR} using a cooperative game framework and covering decision-theoretic models such as the Interface Card Model and Probability Ranking Principle for {IIR}. Next, it provides a review of some representative specific techniques and algorithms for {IIR}, such as various forms of feedback techniques and diversification of search results, followed by a discussion of how an {IIR} system should be evaluated and multiple strategies proposed recently for evaluating {IIR} using user simulation. The tutorial ends with a brief discussion of the major open challenges in {IIR} and some of the most promising future research directions.},
	pages = {2444--2447},
	booktitle = {Proceedings of the 43rd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {Association for Computing Machinery},
	author = {Zhai, {ChengXiang}},
	urldate = {2022-06-07},
	date = {2020-07-25},
	keywords = {interactive information retrieval, mathematical models of retrieval, search engines, user interaction},
}

@article{kelly_methods_2009,
	title = {Methods for Evaluating Interactive Information Retrieval Systems with Users},
	volume = {3},
	issn = {1554-0669},
	url = {https://doi.org/10.1561/1500000012},
	doi = {10.1561/1500000012},
	abstract = {This paper provides overview and instruction regarding the evaluation of interactive information retrieval systems with users. The primary goal of this article is to catalog and compile material related to this topic into a single source. This article (1) provides historical background on the development of user-centered approaches to the evaluation of interactive information retrieval systems; (2) describes the major components of interactive information retrieval system evaluation; (3) describes different experimental designs and sampling strategies; (4) presents core instruments and data collection techniques and measures; (5) explains basic data analysis techniques; and (4) reviews and discusses previous studies. This article also discusses validity and reliability issues with respect to both measures and methods, presents background information on research ethics and discusses some ethical issues which are specific to studies of interactive information retrieval ({IIR}). Finally, this article concludes with a discussion of outstanding challenges and future research directions.},
	pages = {1--224},
	number = {1},
	journaltitle = {Foundations and Trends in Information Retrieval},
	shortjournal = {Found. Trends Inf. Retr.},
	author = {Kelly, Diane},
	urldate = {2022-06-07},
	date = {2009-01-01},
}

@article{ruthven_interactive_2008,
	title = {Interactive Information Retrieval},
	pages = {50},
	author = {Ruthven, Ian},
	date = {2008},
	langid = {english},
	file = {Ruthven - Interactive Information Retrieval.pdf:C\:\\Users\\vimio\\Zotero\\storage\\HR7BVULB\\Ruthven - Interactive Information Retrieval.pdf:application/pdf},
}

@inproceedings{scells_big_2021-1,
	location = {New York, {NY}, {USA}},
	title = {\textit{Big Brother:} A Drop-In Website Interaction Logging Service},
	isbn = {978-1-4503-8037-9},
	url = {https://doi.org/10.1145/3404835.3462781},
	doi = {10.1145/3404835.3462781},
	series = {{SIGIR} '21},
	shorttitle = {{\textless}i{\textgreater}Big Brother},
	abstract = {Fine-grained logging of interactions in user studies is important for studying user behaviour, among other reasons. However, in many research scenarios, the way interactions are logged is usually tied to a monolithic system. We present a generic, application-independent service for logging interactions in web-pages, specifically targetting user studies. Our service, Big Brother, can be dropped-in to existing user interfaces with almost no configuration required by researchers. Big Brother has already been used in several user studies to record interactions in a number of user study research scenarios, such as lab-based and crowdsourcing environments. We further demonstrate the ability for Big Brother to scale to very large user studies through benchmarking experiments. Big Brother also provides a number of additional tools for visualising and analysing interactions. Big Brother significantly lowers the barrier to entry for logging user interactions by providing a minimal but powerful, no configuration necessary, service for researchers and practitioners of user studies that can scale to thousands of concurrent sessions. We have made the source code and releases for Big Brother available for download at https://github.com/hscells/bigbro.},
	pages = {2590--2594},
	booktitle = {Proceedings of the 44th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {Association for Computing Machinery},
	author = {Scells, Harrisen and Jimmy and Zuccon, Guido},
	urldate = {2022-06-07},
	date = {2021-07-11},
	keywords = {interaction logging, user studies},
	file = {Accepted Version:C\:\\Users\\vimio\\Zotero\\storage\\PYEYWUHT\\Scells et al. - 2021 - Big Brother A Drop-In Website Interaction .pdf:application/pdf},
}

@article{breuer_living_2021,
	title = {A Living Lab Architecture for Reproducible Shared Task Experimentation},
	abstract = {No existing evaluation infrastructure for shared tasks currently supports both reproducible on- and offline experiments. In this work, we present an architecture that ties together both types of experiments with a focus on reproducibility. The readers are provided with a technical description of the infrastructure and details of how to contribute their own experiments to upcoming evaluation tasks.},
	pages = {15},
	journaltitle = {Emerging Technologies},
	author = {Breuer, Timo and Schaer, Philipp},
	date = {2021},
	langid = {english},
	file = {Breuer and Schaer - A Living Lab Architecture for Reproducible Shared .pdf:C\:\\Users\\vimio\\Zotero\\storage\\B3LTG3FM\\Breuer and Schaer - A Living Lab Architecture for Reproducible Shared .pdf:application/pdf},
}

@book{breuer_evaluating_2022,
	title = {Evaluating Elements of Web-based Data Enrichment for Pseudo-Relevance Feedback Retrieval},
	abstract = {In this work, we analyze a pseudo-relevance retrieval method based on the results of web search engines. By enriching topics with text data from web search engine result pages and linked contents, we train topic-specific and cost-efficient classifiers that can be used to search test collections for relevant documents. Building upon attempts initially made at {TREC} Common Core 2018 by Grossman and Cormack, we address questions of system performance over time considering different search engines, queries, and test collections. Our experimental results show how and to which extent the considered components affect the retrieval performance. Overall, the analyzed method is robust in terms of average retrieval performance and a promising way to use web content for the data enrichment of relevance feedback methods.},
	author = {Breuer, Timo and Pest, Melanie and Schaer, Philipp},
	date = {2022-03-10},
}

@incollection{schaer_living_2021,
	title = {Living Lab Evaluation for Life and Social Sciences Search Platforms - {LiLAS} at {CLEF} 2021},
	isbn = {978-3-030-72239-5},
	abstract = {Meta-evaluation studies of system performances in controlled offline evaluation campaigns, like {TREC} and {CLEF}, show a need for innovation in evaluating {IR}-systems. The field of academic search is no exception to this. This might be related to the fact that relevance in academic search is multi-layered and therefore the aspect of user-centric evaluation is becoming more and more important. The Living Labs for Academic Search ({LiLAS}) lab aims to strengthen the concept of user-centric living labs for the domain of academic search by allowing participants to evaluate their retrieval approaches in two real-world academic search systems from the life sciences and the social sciences. To this end, we provide participants with metadata on the systems’ content as well as candidate lists with the task to rank the most relevant candidate to the top. Using the {STELLA}-infrastructure, we allow participants to easily integrate their approaches into the real-world systems and provide the possibility to compare different approaches at the same time.},
	pages = {657--664},
	author = {Schaer, Philipp and Schaible, Johann and Castro, Leyla},
	date = {2021-03-30},
	doi = {10.1007/978-3-030-72240-1_77},
}

@inproceedings{putra_searchx_2018,
	location = {Ann Arbor {MI} {USA}},
	title = {{SearchX}: Empowering Collaborative Search Research},
	isbn = {978-1-4503-5657-2},
	url = {https://dl.acm.org/doi/10.1145/3209978.3210163},
	doi = {10.1145/3209978.3210163},
	shorttitle = {{SearchX}},
	abstract = {Collaborative search has been an active area of research within the {IR} community for many years. While for “single-user” research a variety of up-to-date open-source search systems exist, few “multiuser” search tools are open-source and even fewer are being maintained. In this paper, we present {SearchX}, an open-source collaborative search system we are currently developing—and using for our research. We designed and built {SearchX} using the modern Web stack (and are thus not siloed by an operating system or a particular browser type), enabling efficient research across platforms (Desktop, mobile) and with online users (e.g. crowdworkers). A video, describing the demo can be found at https: //www.youtube.com/watch?v=uf24m6p3vts.},
	eventtitle = {{SIGIR} '18: The 41st International {ACM} {SIGIR} conference on research and development in Information Retrieval},
	pages = {1265--1268},
	booktitle = {The 41st International {ACM} {SIGIR} Conference on Research \& Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Putra, Sindunuraga Rikarno and Moraes, Felipe and Hauff, Claudia},
	urldate = {2022-06-07},
	date = {2018-06-27},
	langid = {english},
	file = {Putra et al. - 2018 - SearchX Empowering Collaborative Search Research.pdf:C\:\\Users\\vimio\\Zotero\\storage\\TBTT5M29\\Putra et al. - 2018 - SearchX Empowering Collaborative Search Research.pdf:application/pdf},
}

@online{intersoft_consulting_general_2022,
	title = {General Data Protection Regulation ({GDPR}) – Official Legal Text},
	url = {https://gdpr-info.eu/},
	abstract = {General Data Protection Regulation ({EU} {GDPR}) – The official {PDF} of the Regulation ({EU}) 2016/679, its recitals \& key issues as a neatly arranged website.},
	titleaddon = {General Data Protection Regulation ({GDPR})},
	author = {Intersoft Consulting},
	urldate = {2022-06-07},
	date = {2022},
	langid = {american},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\6DYBTKA9\\gdpr-info.eu.html:text/html},
}

@online{bonta_california_2018,
	title = {California Consumer Privacy Act ({CCPA})},
	url = {https://oag.ca.gov/privacy/ccpa},
	abstract = {The California Consumer Privacy Act of 2018 ({CCPA}) gives consumers more control over the personal information that businesses collect about them and the {CCPA} regulations provide guidance on how to implement the law.},
	titleaddon = {State of California - Department of Justice - Office of the Attorney General},
	author = {Bonta, Rob},
	urldate = {2022-06-07},
	date = {2018-10-15},
	langid = {english},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\YGWNZJY5\\ccpa.html:text/html},
}

@article{borlund_interactive_2013,
	title = {Interactive Information Retrieval: An Introduction},
	volume = {1},
	doi = {10.1633/JISTaP.2013.1.3.2},
	shorttitle = {Interactive Information Retrieval},
	abstract = {The paper introduces the research area of interactive information retrieval ({IIR}) from a historical point of view. Further, the focus here is on evaluation, because much research in {IR} deals with {IR} evaluation methodology due to the core research interest in {IR} performance, system interaction and satisfaction with retrieved information. In order to position {IIR} evaluation, the Cranfield model and the series of tests that led to the Cranfield model are outlined. Three iconic user-oriented studies and projects that all have contributed to how {IIR} is perceived and understood today are presented: The {MEDLARS} test, the Book House fiction retrieval system, and the {OKAPI} project. On this basis the call for alternative {IIR} evaluation approaches motivated by the three revolutions (the cognitive, the relevance, and the interactive revolutions) put forward by Robertson \& Hancock-Beaulieu (1992) is presented. As a response to this call the '{IIR} evaluation model' by Borlund (e.g., 2003a) is introduced. The objective of the {IIR} evaluation model is to facilitate {IIR} evaluation as close as possible to actual information searching and {IR} processes, though still in a relatively controlled evaluation environment, in which the test instrument of a simulated work task situation plays a central part.},
	journaltitle = {Journal of Information Science Theory and Practice},
	shortjournal = {Journal of Information Science Theory and Practice},
	author = {Borlund, Pia},
	date = {2013-09-30},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\MG6MEHJG\\Borlund - 2013 - Interactive Information Retrieval An Introduction.pdf:application/pdf},
}

@inproceedings{belkin_ecir_2008,
	title = {{ECIR} {KEYNOTE} Some(what) Grand Challenges for Information Retrieval 1},
	volume = {42},
	isbn = {978-3-540-78645-0},
	doi = {10.1007/978-3-540-78646-7_1},
	abstract = {Although we see the positive results of information retrieval research embodied throughout the Internet, on our computer desktops, and in many other aspects of daily life, at the same time we notice that people still have a wide variety of difficulties in finding information that is useful in resolving their problematic situations. This suggests that there still remain substantial challenges for research in {IR}. Already in 1988, on the occasion of receiving the {ACM} {SIGIR} Gerard Salton Award, Karen Spärck Jones suggested that substantial progress in information retrieval was likely only to come through addressing issues associated with users (actual or potential) of {IR} systems, rather than continuing {IR} research's almost exclusive focus on document representation and matching and ranking techniques. In recent years it appears that her message has begun to be heard, yet we still have relatively few substantive results that respond to it. In this paper, I identify and discuss a few challenges for {IR} research which fall within the scope of association with users, and which I believe, if properly addressed, are likely to lead to substantial increases in the usefulness, usability and pleasurability of information retrieval.},
	eventtitle = {{SIGIR} Forum},
	pages = {47--54},
	author = {Belkin, Nicholas},
	date = {2008-06-01},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\J4QTWNE9\\Belkin - 2008 - ECIR KEYNOTE Some(what) Grand Challenges for Infor.pdf:application/pdf},
}

@article{ferro_report_2016,
	title = {Report on {ECIR} 2016: 38th European Conference on Information Retrieval},
	volume = {50},
	issn = {0163-5840},
	url = {https://dl.acm.org/doi/10.1145/2964797.2964801},
	doi = {10.1145/2964797.2964801},
	shorttitle = {Report on {ECIR} 2016},
	abstract = {The 38th European Conference on Information Retrieval took place from the 20th to the 23rd of March 2016 in Padua, Italy. This report summarizes the conference in terms of the presented keynotes, scientific and social programme, industry day, tutorials, workshops and student support.},
	pages = {12--27},
	number = {1},
	journaltitle = {{ACM} {SIGIR} Forum},
	shortjournal = {{SIGIR} Forum},
	author = {Ferro, Nicola and Crestani, Fabio and Moens, Marie-Francine and Mothe, Josiane and Silvestri, Fabrizio and Kekäläinen, Jaana and Rosso, Paolo and Clough, Paul and Pasi, Gabriella and Lioma, Christina and Mizzaro, Stefano and Di Nunzio, Giorgio Maria and Hauff, Claudia and Alonso, Omar and Serdyukov, Pavel and Silvello, Gianmaria},
	urldate = {2022-06-08},
	date = {2016-06-27},
	langid = {english},
	file = {Ferro et al. - 2016 - Report on ECIR 2016 38th European Conference on I.pdf:C\:\\Users\\vimio\\Zotero\\storage\\ZWSGPDMM\\Ferro et al. - 2016 - Report on ECIR 2016 38th European Conference on I.pdf:application/pdf},
}

@online{text_retrieval_conference_trec_text_2022,
	title = {Text {REtrieval} Conference ({TREC}) Home Page},
	url = {https://trec.nist.gov/},
	author = {Text {REtrieval} Conference ({TREC})},
	urldate = {2022-06-08},
	date = {2022},
	file = {Text REtrieval Conference (TREC) Home Page:C\:\\Users\\vimio\\Zotero\\storage\\MFJ84HFK\\trec.nist.gov.html:text/html},
}

@online{noauthor_okapi_2022,
	title = {The {OKAPI} information retrieval},
	url = {https://arkiv.inf.ku.dk/KoLifeboat/SPECIFIC%20SYSTEMS/okapi_information_retrieval.htm},
	urldate = {2022-06-08},
	date = {2022},
	file = {The OKAPI information retrieval:C\:\\Users\\vimio\\Zotero\\storage\\ZGY7MXUN\\okapi_information_retrieval.html:text/html},
}

@online{borlund_iir_2003,
	title = {The {IIR} evaluation model: a framework for evaluation of interactive information retrieval systems},
	rights = {http://creativecommons.org/licenses/by-nd-nc/1.0/},
	url = {http://informationr.net/ir/8-3/paper152.html},
	shorttitle = {The {IIR} evaluation model},
	abstract = {An alternative approach to evaluation of interactive information retrieval ({IIR}) systems, referred to as the {IIR} evaluation model, is proposed.  The model provides a framework for the collection and analysis of {IR} interaction data.  The aim of the model is two-fold: 1) to facilitate the evaluation of {IIR} systems as realistically as possible with reference to actual information searching and retrieval processes, though still in a relatively controlled evaluation environment; and 2) to calculate the {IIR} system performance taking into account the non-binary nature of the assigned relevance assessments.  The {IIR} evaluation model is presented as an alternative to the system-driven Cranfield model which still is the dominant approach to the evaluation of {IR} and {IIR} systems.  Key elements of the {IIR} evaluation model are the  use of realistic scenarios, known as simulated work task situations, and the (call for) alternative performance measures.  A simulated work task situation, which is a short ‘cover story’, serves two main functions: 1) it triggers and develops a simulated information need by allowing for user interpretations of the situation, leading to cognitively individual information need interpretations as in real life; and 2) it is the platform against which situational relevance is judged.  Further, by being the same for all test persons experimental control is provided.  Hence, the concept of a simulated work task situation ensures the experiment both realism and control.  Guidelines and recommendations for the application of simulated work task situations are provided.  Examples of alternative performance measures are: relative relevance ({RR}), ranked half-life ({RHL}), cumulated gain ({CG}) and cumulated gain with discount ({DCG}). These measures can incorporate non-binary relevance assessments, necessary due to the result of realistic interaction and relevance assessment behaviour of users in the process of searching and assessing relevance of retrieved information objects.},
	type = {text},
	author = {Borlund, Pia},
	urldate = {2022-06-08},
	date = {2003},
	langid = {english},
	note = {{ISSN}: 1368-1613
Publisher: Professor T.D. Wilson},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\YUCKLPIW\\paper152.html:text/html},
}

@article{borlund_concept_2003,
	title = {The concept of relevance in {IR}},
	volume = {54},
	doi = {10.1002/asi.10286},
	abstract = {This article introduces the concept of relevance as viewed and applied in the context of {IR} evaluation, by presenting an overview of the multidimensional and dynamic nature of the concept. The literature on relevance reveals how the relevance concept, especially in regard to the multidimensionality of relevance, is many faceted, and does not just refer to the various relevance criteria users may apply in the process of judging relevance of retrieved information objects. From our point of view, the multidimensionality of relevance explains why some will argue that no consensus has been reached on the relevance concept. Thus, the objective of this article is to present an overview of the many different views and ways by which the concept of relevance is used--leading to a consistent and compatible understanding of the concept. In addition, special attention is paid to the type of situational relevance. Many researchers perceive situational relevance as the most realistic type of user relevance, and therefore situational relevance is discussed with reference to its potential dynamic nature, and as a requirement for interactive information retrieval ({IIR}) evaluation.},
	pages = {913--925},
	journaltitle = {{JASIST}},
	shortjournal = {{JASIST}},
	author = {Borlund, Pia},
	date = {2003-08-01},
}

@inproceedings{borlund_measures_1998,
	title = {Measures of Relative Relevance and Ranked Half-Life: Performance Indicators for Interactive {IR}.},
	doi = {10.1145/290941.291019},
	shorttitle = {Measures of Relative Relevance and Ranked Half-Life},
	abstract = {This paper introduces the concepts of the relative relevance ({RR}) measure and a new performance indicator of the positional strength of the retrieved and ranked documents. The former is seen as a measure of associative performance computed by the application of the Jaccard formula. The latter is named the Ranked Half-Life ({RHL}) indicator and denotes the degree to which relevant documents are located on the top of a ranked retrieval result. The measures are proposed to be applied in addition to the traditional performance parameters such as precision and/or recall in connection with evaluation of interactive {IR} systems. The {RR} measure describes the degree of agreement between the types of relevance applied in evaluation of information retrieval ({IR}) systems in a non-binary assessment context. It is shown that the measure has potential to bridge the gap between subjective and objective relevance, as it makes it possible to understand and interpret the relation between these two main classes of relevance used in toteractive {IR} experiments. The relevance concepts are defined, and the application of the measures is demonstrated by interrelating three types of relevance assessments: algorithmic; intellectual topicality and; situational assessments. Further, the paper shows that for a given set of queries at given precision levels the {RHL} indicator adds to the understanding of comparisons of {IR} performance.},
	pages = {324--331},
	author = {Borlund, Pia and Ingwersen, Peter},
	date = {1998-01-01},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\IUQV3KTK\\Borlund and Ingwersen - 1998 - Measures of Relative Relevance and Ranked Half-Lif.pdf:application/pdf},
}

@article{robertson_overview_1997,
	title = {Overview of the Okapi projects},
	volume = {53},
	issn = {0022-0418},
	url = {https://doi.org/10.1108/EUM0000000007186},
	doi = {10.1108/EUM0000000007186},
	abstract = {This paper gives a brief description of the Okapi projects and the work of the Centre for Interactive Systems research, as an introduction to this special issue of the Journal of Documentation. Okapi is the name given to an experimental text retrieval system (or rather, family of systems, as will be discussed below), based at City University, London. The current systems and their predecessors have been used as the basis for a series of projects, generally addressing aspects of user information‐seeking behaviour and user‐system interaction, as well as system design. The projects have been supported extensively by the British Library, and to some degree by a number of other funders. They have been at City since 1989; for the previous seven years they were based at the Polytechnic of Central London (now the University of Westminster). In order to give a picture of the system(s) that now constitute Okapi, it is appropriate to describe one version containing some of the features that have become central to the Okapi projects, and then to indicate the variety of systems now implemented or implementable within the present setup, as well as the directions it may go in the future. In what follows, papers in this issue are referred to by brief titles.},
	pages = {3--7},
	number = {1},
	journaltitle = {Journal of Documentation},
	author = {Robertson, S.E.},
	urldate = {2022-06-08},
	date = {1997-01-01},
	note = {Publisher: {MCB} {UP} Ltd},
	keywords = {Document management, Okapi system, Text retrieval},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\VTP6INWQ\\html.html:text/html},
}

@article{robertson_evaluation_1992,
	title = {On the evaluation of {IR} systems},
	volume = {28},
	issn = {0306-4573},
	url = {https://doi.org/10.1016/0306-4573(92)90004-J},
	doi = {10.1016/0306-4573(92)90004-J},
	pages = {457--466},
	number = {4},
	journaltitle = {Information Processing and Management: an International Journal},
	shortjournal = {Inf. Process. Manage.},
	author = {Robertson, S. E. and Hancock-Beaulieu, M. M.},
	urldate = {2022-06-08},
	date = {1992-03-01},
}

@incollection{mothe_overview_2015,
	location = {Cham},
	title = {Overview of the Living Labs for Information Retrieval Evaluation ({LL}4IR) {CLEF} Lab 2015},
	volume = {9283},
	isbn = {978-3-319-24026-8 978-3-319-24027-5},
	url = {http://link.springer.com/10.1007/978-3-319-24027-5_47},
	abstract = {In this paper we report on the ﬁrst Living Labs for Information Retrieval Evaluation ({LL}4IR) {CLEF} Lab. Our main goal with the lab is to provide a benchmarking platform for researchers to evaluate their ranking systems in a live setting with real users in their natural task environments. For this ﬁrst edition of the challenge we focused on two speciﬁc use-cases: product search and web search. Ranking systems submitted by participants were experimentally compared using interleaved comparisons to the production system from the corresponding use-case. In this paper we describe how these experiments were performed, what the resulting outcomes are, and conclude with some lessons learned.},
	pages = {484--496},
	booktitle = {Experimental {IR} Meets Multilinguality, Multimodality, and Interaction},
	publisher = {Springer International Publishing},
	author = {Schuth, Anne and Balog, Krisztian and Kelly, Liadh},
	editor = {Mothe, Josanne and Savoy, Jacques and Kamps, Jaap and Pinel-Sauvagnat, Karen and Jones, Gareth and San Juan, Eric and Capellato, Linda and Ferro, Nicola},
	urldate = {2022-06-08},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-319-24027-5_47},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Schuth et al. - 2015 - Overview of the Living Labs for Information Retrie.pdf:C\:\\Users\\vimio\\Zotero\\storage\\6YU8MPK5\\Schuth et al. - 2015 - Overview of the Living Labs for Information Retrie.pdf:application/pdf},
}

@incollection{mothe_overview_2015-1,
	location = {Cham},
	title = {Overview of the Living Labs for Information Retrieval Evaluation ({LL}4IR) {CLEF} Lab 2015},
	volume = {9283},
	isbn = {978-3-319-24026-8 978-3-319-24027-5},
	url = {http://link.springer.com/10.1007/978-3-319-24027-5_47},
	abstract = {In this paper we report on the ﬁrst Living Labs for Information Retrieval Evaluation ({LL}4IR) {CLEF} Lab. Our main goal with the lab is to provide a benchmarking platform for researchers to evaluate their ranking systems in a live setting with real users in their natural task environments. For this ﬁrst edition of the challenge we focused on two speciﬁc use-cases: product search and web search. Ranking systems submitted by participants were experimentally compared using interleaved comparisons to the production system from the corresponding use-case. In this paper we describe how these experiments were performed, what the resulting outcomes are, and conclude with some lessons learned.},
	pages = {484--496},
	booktitle = {Experimental {IR} Meets Multilinguality, Multimodality, and Interaction},
	publisher = {Springer International Publishing},
	author = {Schuth, Anne and Balog, Krisztian and Kelly, Liadh},
	editor = {Mothe, Josanne and Savoy, Jacques and Kamps, Jaap and Pinel-Sauvagnat, Karen and Jones, Gareth and San Juan, Eric and Capellato, Linda and Ferro, Nicola},
	urldate = {2022-06-08},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-319-24027-5_47},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Schuth et al. - 2015 - Overview of the Living Labs for Information Retrie.pdf:C\:\\Users\\vimio\\Zotero\\storage\\N6BXJV6Q\\Schuth et al. - 2015 - Overview of the Living Labs for Information Retrie.pdf:application/pdf},
}

@inproceedings{schaer_living_2020,
	location = {Berlin, Heidelberg},
	title = {Living Labs for Academic Search at {CLEF} 2020},
	isbn = {978-3-030-45441-8},
	url = {https://doi.org/10.1007/978-3-030-45442-5_75},
	doi = {10.1007/978-3-030-45442-5_75},
	abstract = {The need for innovation in the field of academic search and {IR}, in general, is shown by the stagnating system performance in controlled evaluation campaigns, as demonstrated in {TREC} and {CLEF} meta-evaluation studies, as well as user studies in real systems of scientific information and digital libraries. The question of what constitutes relevance in academic search is multi-layered and a topic that drives research communities for years. The Living Labs for Academic Search ({LiLAS}) workshop has the goal to inspire the discussion on research and evaluation of academic search systems by strengthening the concept of living labs to the domain of academic search. We want to bring together {IR} researchers interested in online evaluations of academic search systems and foster knowledge on improving the search for academic resources like literature, research data, and the interlinking between these resources. The employed online evaluation approach based on a living lab infrastructure allows the direct connection to real-world academic search systems from the life sciences and the social sciences.},
	pages = {580--586},
	booktitle = {Advances in Information Retrieval: 42nd European Conference on {IR} Research, {ECIR} 2020, Lisbon, Portugal, April 14–17, 2020, Proceedings, Part {II}},
	publisher = {Springer-Verlag},
	author = {Schaer, Philipp and Schaible, Johann and Müller, Bernd},
	urldate = {2022-06-08},
	date = {2020-04-14},
	keywords = {Academic search, {CLEF}, Evaluation, Living labs},
}

@article{leminen_coordination_2013,
	title = {Coordination and Participation in Living Lab Networks},
	volume = {3},
	issn = {1927-0321},
	pages = {5--14},
	number = {1},
	journaltitle = {Technology Innovation Management Review},
	author = {Leminen, Seppo},
	date = {2013},
	note = {Place: Ottawa
Publisher: Talent First Network},
	file = {Coordination and Participation in Living Lab Networks | TIM Review:C\:\\Users\\vimio\\Zotero\\storage\\XLY9KIN7\\740.html:text/html},
}

@article{schuth_extended_2015,
	title = {Extended Overview of the Living Labs for Information Retrieval Evaluation ({LL}4IR) {CLEF} Lab 2015},
	abstract = {In this extended overview paper we discuss the ﬁrst Living Labs for Information Retrieval Evaluation ({LL}4IR) lab which was held at {CLEF} 2015. The idea with living labs is to provide a benchmarking platform for researchers to evaluate their ranking systems in a live setting with real users in their natural task environments. {LL}4IR represents the ﬁrst attempt to offer such experimental platform to the {IR} research community in the form of a community challenge. For this ﬁrst edition of the challenge we focused on two speciﬁc use-cases: product search and web search. Ranking systems submitted by participants were experimentally compared using interleaved comparisons to the production system from the corresponding use-case. In this paper we describe how these experiments were performed, what the resulting outcomes are, and provide a detailed analysis of the use-cases and a discussion of ideas and opportunities for future development.},
	pages = {22},
	author = {Schuth, Anne and Balog, Krisztian and Kelly, Liadh},
	date = {2015},
	langid = {english},
	file = {Schuth et al. - Extended Overview of the Living Labs for Informati.pdf:C\:\\Users\\vimio\\Zotero\\storage\\GCLUE7GJ\\Schuth et al. - Extended Overview of the Living Labs for Informati.pdf:application/pdf},
}

@article{yu_ictnet_2017,
	title = {{ICTNET} at {TREC}2017 {OpenSearch} Track},
	pages = {3},
	author = {Yu, Xiaoming},
	date = {2017},
	langid = {english},
	file = {Yu - ICTNET at TREC2017 OpenSearch Track.pdf:C\:\\Users\\vimio\\Zotero\\storage\\ZVCZ2GLE\\Yu - ICTNET at TREC2017 OpenSearch Track.pdf:application/pdf},
}

@online{fissac_living_2022,
	title = {Living Labs {\textbar} {FISSAC}},
	url = {https://fissacproject.eu/en/living-labs/},
	author = {{FISSAC}},
	urldate = {2022-06-08},
	date = {2022},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\EEMPDMTH\\living-labs.html:text/html},
}

@online{noauthor_living_2017,
	title = {Living Labs for Online Evaluation {\textbar} Veranstaltungskalender der Universität Freiburg},
	url = {https://agenda.unifr.ch/e/de/2390/},
	urldate = {2022-06-08},
	date = {2017},
	file = {Living Labs for Online Evaluation | Veranstaltungskalender der Universität Freiburg:C\:\\Users\\vimio\\Zotero\\storage\\DVXRFDNK\\2390.html:text/html},
}

@online{stella_stella_2022,
	title = {{STELLA} Infrastructures for Living Labs},
	url = {https://stella-project.org/},
	author = {{STELLA}},
	urldate = {2022-06-08},
	date = {2022},
	file = {Home - STELLA Infrastructures for Living Labs:C\:\\Users\\vimio\\Zotero\\storage\\696EFFNY\\stella-project.org.html:text/html},
}

@article{ferro_increasing_2016,
	title = {Increasing Reproducibility in {IR}: Findings from the Dagstuhl Seminar on "Reproducibility of Data-Oriented Experiments in e-Science"},
	volume = {50},
	issn = {0163-5840},
	url = {https://dl.acm.org/doi/10.1145/2964797.2964808},
	doi = {10.1145/2964797.2964808},
	shorttitle = {Increasing Reproducibility in {IR}},
	abstract = {Reproducibility is a central aspect of offline as well as online evaluations, to validate the results of different teams and in different experimental setups. However, often it is difficult or not even possible to reproduce an online evaluation, as solely a few data providers give access to their system, and if they do, it is limited in time and typically only during an official challenge. To alleviate the situation, we propose {STELLA}: a living lab infrastructure with consistent access to a data provider’s system, which can be used to train and evaluate search- and recommender algorithms. In this position paper, we align {STELLA}’s architecture to the {PRIMAD} model and its six different components specifying reproducibility in online evaluations and illustrate two use cases with two academic search systems.},
	pages = {68--82},
	number = {1},
	journaltitle = {{ACM} {SIGIR} Forum},
	shortjournal = {{SIGIR} Forum},
	author = {Ferro, Nicola and Fuhr, Norbert and Järvelin, Kalervo and Kando, Noriko and Lippold, Matthias and Zobel, Justin},
	urldate = {2022-06-08},
	date = {2016-06-27},
	langid = {english},
	file = {Ferro et al. - 2016 - Increasing Reproducibility in IR Findings from th.pdf:C\:\\Users\\vimio\\Zotero\\storage\\AS97RSV2\\Ferro et al. - 2016 - Increasing Reproducibility in IR Findings from th.pdf:application/pdf},
}

@book{breuer_stella_2019,
	title = {{STELLA}: Towards a Framework for the Reproducibility of Online Search Experiments},
	shorttitle = {{STELLA}},
	abstract = {Reproducibility is a central aspect of offline as well as online evaluations , to validate the results of different teams and in different experimental setups. However, often it is difficult or not even possible to reproduce an online evaluation, as solely a few data providers give access to their system, and if they do, it is limited in time and typically only during an official challenge. To alleviate the situation, we propose {STELLA}: a living lab infrastructure with consistent access to a data provider's system, which can be used to train and evaluate search-and recommender algorithms. In this position paper , we align {STELLA}'s architecture to the {PRIMAD} model and its six different components specifying reproducibility in online evaluations and illustrate two use cases with two academic search systems.},
	author = {Breuer, Timo and Schaer, Philipp and Tavakolpoursaleh, Narges and Schaible, Johann and Wolff, Benjamin and Müller, Bernd},
	date = {2019-07-03},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\X2QW3E9K\\Breuer et al. - 2019 - STELLA Towards a Framework for the Reproducibilit.pdf:application/pdf},
}

@book{shneiderman_designing_1997,
	location = {{USA}},
	edition = {3rd},
	title = {Designing the User Interface: Strategies for Effective Human-Computer Interaction},
	isbn = {978-0-201-69497-0},
	shorttitle = {Designing the User Interface},
	abstract = {From the Publisher: In 1996, recognizing this book, {ACM}'s Special Interest Group on Documentation ({SIGDOC}) presented Ben Shneiderman with the Joseph Rigo Award. {SIGDOC} praised the book as one "that took the jargon and mystery out of the field of human-computer interaction" and attributed the book's success to "its readability and emphasis on practice as well as research." In revising this best-seller, Ben Shneiderman again provides a complete, current, and authoritative introduction to user-interface design. The user interface is the part of every computer system that determines how people control and operate that system. When the interface is well designed, it is comprehensible, predictable, and controllable; users feel competent, satisfied, and responsible for their actions. In this book, the author discusses the principles and practices needed to design such effective interaction. Based on 20 years experience, Shneiderman offers readers practical techniques and guidelines for interface design. As a scientist, he also takes great care to discuss underlying issues and to support conclusions with empirical results. Interface designers, software engineers, and product managers will all find here an invaluable resource for creating systems that facilitate rapid learning and performance, yield low error rates, and generate high user satisfaction. Coverage includes the human factors of interactive software (with added discussion of diverse user communities), tested methods to develop and assess interfaces, interaction styles (like direct manipulation for graphical user interfaces), and design considerations (effective messages, consistent screen design, appropriate color).},
	pagetotal = {639},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	author = {Shneiderman, Ben},
	date = {1997},
}

@article{philips_usability_1990,
	title = {Usability Testing: Identifying Functional Requirements for Data Logging Software},
	volume = {34},
	issn = {0163-5182},
	url = {https://doi.org/10.1177/154193129003400412},
	doi = {10.1177/154193129003400412},
	shorttitle = {Usability Testing},
	abstract = {One of the new tools in human factors today is usability testing. More and more human factors professionals are conducting these tests to get accurate feedback from typical users to improve the usability, overall quality, and sales of their products. American Institutes for Research has been doing usability testing for five years now and have discussed testing with the directors of many labs. We have a body of knowledge and experience from which other professionals can benefit. In particular, we will be discussing data logging software and the functional requirements for it. In this paper we will describe the requirements for data logging software to log data, edit the data log, back up data and analyze data., Due to the scarcity of commercially available data logging packages (we know of only one at the present time) we found it necessary to write our own software for use in our usability lab and we know others are doing the same. Based on our experience of writing and using this software, we will describe the important functional requirements for data logging software.},
	pages = {295--299},
	number = {4},
	journaltitle = {Proceedings of the Human Factors Society Annual Meeting},
	shortjournal = {Proceedings of the Human Factors Society Annual Meeting},
	author = {Philips, Brian H. and Dumas, Joseph S.},
	urldate = {2022-06-09},
	date = {1990-10-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications},
}

@book{noauthor_advances_2021,
	title = {Advances in Information Retrieval},
	url = {https://link.springer.com/book/10.1007/978-3-030-72240-1},
	abstract = {The conference proceedings {ECIR} 2021 presents papers of Information retrieval, Interactive information retrieval and much more.},
	urldate = {2022-06-09},
	date = {2021},
	langid = {english},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\R7GCUDIR\\978-3-030-72240-1.html:text/html},
}

@online{noauthor_proceedings_nodate,
	title = {Proceedings of the 44th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	url = {https://dl.acm.org/doi/proceedings/10.1145/3404835},
	titleaddon = {{ACM} Conferences},
	urldate = {2022-06-09},
	langid = {english},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\XSFE2RD4\\3404835.html:text/html},
}

@article{hoiem_designing_1994,
	title = {Designing and using integrated data collection and analysis tools: challenges and considerations},
	volume = {13},
	issn = {0144-929X},
	url = {https://doi.org/10.1080/01449299408914595},
	doi = {10.1080/01449299408914595},
	shorttitle = {Designing and using integrated data collection and analysis tools},
	abstract = {This paper describes the design and evolution of mi integrated set of computer-aided usability engineering ({CAUSE}) tools for data collection and analysis. The tools were designed to collect and analyse observational, video, and system event data in both the usability laboratory and in the field. Three generations of tools are described and the problems with each generation are discussed. Solutions to the problems arc presented, where available. Conclusions about the strengths and weaknesses of particular types of data, {CAUSE} tool design, and the importance of multiple data sources are drawn. An agenda for future work is also outlined.},
	pages = {160--170},
	number = {1},
	journaltitle = {Behaviour \& Information Technology},
	author = {{HOIEM}, {DEREK} E. and {SULLIVAN}, {KENT} D.},
	urldate = {2022-06-09},
	date = {1994-01-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01449299408914595},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\IAAICBFH\\01449299408914595.html:text/html},
}

@article{zimmerman_observer_2009,
	title = {The Observer {XT}: a tool for the integration and synchronization of multimodal signals},
	volume = {41},
	issn = {1554-351X},
	doi = {10.3758/BRM.41.3.731},
	shorttitle = {The Observer {XT}},
	abstract = {The Observer was originally developed as a manual event recorder for the collection, management, analysis, and presentation of observational data in animals. Because of the flexibility of later versions, it became clear that The Observer was suitable for almost any study involving collection of observational data in both animals and humans. Furthermore, the most recent version of The Observer (The Observer {XT}) allows the integration and synchronization of multimodal signals from various sources, such as observational, video, tracking, and physiological data. This article describes how The Observer {XT} was used to integrate and synchronize video, observational, tracking, and physiological data from an experiment carried out in 2001 at the Wageningen Institute of Animal Sciences of Wageningen University and Research Centre. The integration and synchronization of these multimodal signals in The Observer {XT} allows the user to draw a more complete picture of the phenomena under study.},
	pages = {731--735},
	number = {3},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res Methods},
	author = {Zimmerman, Patrick H. and Bolhuis, J. Elizabeth and Willemsen, Albert and Meyer, Erik S. and Noldus, Lucas P. J. J.},
	date = {2009-08},
	pmid = {19587185},
	keywords = {Animals, Behavioral Research, Data Collection, Electronic Data Processing, Image Processing, Computer-Assisted, Software, Videotape Recording},
	file = {Full Text:C\:\\Users\\vimio\\Zotero\\storage\\3GF27T8I\\Zimmerman et al. - 2009 - The Observer XT a tool for the integration and sy.pdf:application/pdf},
}

@article{trewin_inputlogger_1998,
	title = {{InputLogger}: General-purpose logging of keyboard and mouse events on an Apple Macintosh},
	volume = {30},
	issn = {0743-3808},
	url = {https://www.academia.edu/12249596/InputLogger_General_purpose_logging_of_keyboard_and_mouse_events_on_an_Apple_Macintosh},
	shorttitle = {{InputLogger}},
	abstract = {Event logging, particularly logging of event-timing information, is often used in human-computer interaction research in investigations of the ways in which people use computers and in the evaluation of input devices and applications. This paper},
	pages = {327--331},
	number = {2},
	journaltitle = {Behavior Research Methods, Instruments, \&amp; Computers},
	author = {Trewin, Shari},
	urldate = {2022-06-09},
	date = {1998},
	file = {Snapshot:C\:\\Users\\vimio\\Zotero\\storage\\2YQ5KEI6\\InputLogger_General_purpose_logging_of_keyboard_and_mouse_events_on_an_Apple_Macintosh.html:text/html},
}

@article{berners-lee_world-wide_1994,
	title = {The World-Wide Web},
	volume = {37},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/179606.179671},
	doi = {10.1145/179606.179671},
	pages = {76--82},
	number = {8},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Berners-Lee, Tim and Cailliau, Robert and Luotonen, Ari and Nielsen, Henrik Frystyk and Secret, Arthur},
	urldate = {2022-06-09},
	date = {1994-08-01},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\Q6HQUBW8\\Berners-Lee et al. - 1994 - The World-Wide Web.pdf:application/pdf},
}

@inproceedings{wang_empirical_2012,
	location = {Berlin, Heidelberg},
	title = {An Empirical Study of Dangerous Behaviors in Firefox Extensions},
	isbn = {978-3-642-33383-5},
	doi = {10.1007/978-3-642-33383-5_12},
	series = {Lecture Notes in Computer Science},
	abstract = {Browser extensions provide additional functionality and customization to browsers. To support such functionality, extensions interact with browsers through a set of {APIs} of different privilege levels. As shown in previous studies, browser extensions are often granted more privileges than necessary. Extensions can directly threaten the host system as well as web applications, or bring in indirect threats to web sessions by injecting contents into web pages. In this paper, we make an empirical study to analyze extension behaviors, especially the behaviors that affect web sessions. We developed a dynamic technique to track the behaviors of injected scripts and analyzed the impact of these scripts. We analyzed the behaviors of 2465 extensions and discussed their security implications. We also proposed a solution to mitigate indirect threats to web sessions.},
	pages = {188--203},
	booktitle = {Information Security},
	publisher = {Springer},
	author = {Wang, Jiangang and Li, Xiaohong and Liu, Xuhui and Dong, Xinshu and Wang, Junjie and Liang, Zhenkai and Feng, Zhiyong},
	editor = {Gollmann, Dieter and Freiling, Felix C.},
	date = {2012},
	langid = {english},
	keywords = {Dangerous Behavior, Direct Threat, Extension Behavior, Extension Framework, Password Manager},
}

@article{ter_louw_enhancing_2008,
	title = {Enhancing web browser security against malware extensions},
	volume = {4},
	issn = {1772-9890, 1772-9904},
	url = {http://link.springer.com/10.1007/s11416-007-0078-5},
	doi = {10.1007/s11416-007-0078-5},
	abstract = {In this paper we examine security issues of functionality extension mechanisms supported by web browsers. Extensions (or “plug-ins”) in modern web browsers enjoy unrestrained access at all times and thus are attractive vectors for malware. To solidify the claim, we take on the role of malware writers looking to assume control of a user’s browser space. We have taken advantage of the lack of security mechanisms for browser extensions and implemented a malware application for the popular Firefox web browser, which we call {browserSpy}, that requires no special privileges to be installed. {browserSpy} takes complete control of the user’s browser space, can observe all activity performed through the browser and is undetectable. We then adopt the role of defenders to discuss defense strategies against such malware. Our primary contribution is a mechanism that uses code integrity checking techniques to control the extension installation and loading process. We describe two implementations of this mechanism: a drop-in solution that employs {JavaScript} and a faster, in-browser solution that makes uses of the browser’s native cryptography implementation. We also discuss techniques for runtime monitoring of extension behavior to provide a foundation for defending threats posed by installed extensions.},
	pages = {179--195},
	number = {3},
	journaltitle = {Journal in Computer Virology},
	shortjournal = {J Comput Virol},
	author = {Ter Louw, Mike and Lim, Jin Soon and Venkatakrishnan, V. N.},
	urldate = {2022-06-09},
	date = {2008-08},
	langid = {english},
	file = {Ter Louw et al. - 2008 - Enhancing web browser security against malware ext.pdf:C\:\\Users\\vimio\\Zotero\\storage\\J8V6HQFC\\Ter Louw et al. - 2008 - Enhancing web browser security against malware ext.pdf:application/pdf},
}

@inproceedings{larson_performance_2014,
	title = {Performance analysis of javascript injection detection techniques},
	doi = {10.1109/EIT.2014.6871752},
	abstract = {{JavaScript} injection is inserting unwanted {JavaScript} into Web pages with the intent on violating the security and privacy standards of the Web pages. There are a number of techniques that have been developed for the detection and prevention of {JavaScript} injection, and all have performance costs. While the performance issues of the {JavaScript} injection detection techniques have been mainly studied in running systems, we propose a simulation approach using {UML} {SPT} and {JavaSim}. The new approach not only reduces the cost for such analysis but also provides a framework for modeling injection detection techniques and analyzing the performance implications of design decisions.},
	eventtitle = {{IEEE} International Conference on Electro/Information Technology},
	pages = {140--148},
	booktitle = {{IEEE} International Conference on Electro/Information Technology},
	author = {Larson, David and Liu, Jigang and Zuo, Yanjun},
	date = {2014-06},
	note = {{ISSN}: 2154-0373},
	keywords = {Browsers, Computer Security, Instruction sets, Intrusion Detection, {JavaScript}, performance analysis, Performance analysis, Time factors, Unified modeling language, Web servers},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\vimio\\Zotero\\storage\\V98V5N7I\\6871752.html:text/html},
}

@article{shah_rwels_2008,
	title = {{RWELS}: A Remote Web Event Logging System},
	volume = {20},
	doi = {10.1016/S1319-1578(08)80001-8},
	shorttitle = {{RWELS}},
	abstract = {Event logs are an important data source for identifying usability problems in websites. We present a web-based client-server application, Remote Web Event Logging System ({RWELS}), for logging user-interface events generated in the Microsoft Internet Explorer during a user's interaction with the pages of a website. {RWELS} logs events without interfering with the user's interaction — no additional interaction is required on part of a user to enable logging. {RWELS} is configurable and allows user-centric event logging. A usability analyst can choose the set of events to be captured and the pages of the website to be logged for a particular user. The event logs are dispatched through {HTTP} to the server where they are stored as text files. Users are identified uniquely and the event logs are associated with the user sessions.},
	pages = {1--11},
	journaltitle = {Journal of King Saud University - Computer and Information Sciences},
	shortjournal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Shah, Inayatullah and Toaimy, L. and Jawed, M.},
	date = {2008-12-31},
	file = {Full Text PDF:C\:\\Users\\vimio\\Zotero\\storage\\YMGV4356\\Shah et al. - 2008 - RWELS A Remote Web Event Logging System.pdf:application/pdf},
}

@inproceedings{feild_using_2013,
	location = {New York, {NY}, {USA}},
	title = {Using {CrowdLogger} for in situ information retrieval system evaluation},
	isbn = {978-1-4503-2420-5},
	url = {https://doi.org/10.1145/2513150.2513164},
	doi = {10.1145/2513150.2513164},
	series = {{LivingLab} '13},
	abstract = {A major hurdle faced by many information retrieval researchers---especially in academia---is evaluating retrieval systems in the wild. Challenges include tapping into large user bases, collecting user behavior, and modifying a given retrieval system. We outline several options available to researchers to overcome these challenges along with their advantages and disadvantages. We then demonstrate how {CrowdLogger}, an open-source browser extension for Firefox and Google Chrome, can be used as an in situ evaluation platform.},
	pages = {15--18},
	booktitle = {Proceedings of the 2013 workshop on Living labs for information retrieval evaluation},
	publisher = {Association for Computing Machinery},
	author = {Feild, Henry A. and Allan, James},
	urldate = {2022-06-09},
	date = {2013-11-01},
	keywords = {browser extensions, in situ studies, user studies},
}

@article{fette_websocket_2011,
	title = {The {WebSocket} Protocol},
	doi = {10.17487/rfc6455},
	abstract = {The {WebSocket} Protocol enables two-way communication between a client running untrusted code in a controlled environment to a remote host that has opted-in to communications from that code. The {WebSocket} Protocol enables two-way communication between a client
running untrusted code in a controlled environment to a remote host
that has opted-in to communications from that code. The security model
used for this is the origin-based security model commonly used by web
browsers. The protocol consists of an opening handshake followed by
basic message framing, layered over {TCP}. The goal of this technology
is to provide a mechanism for browser-based applications that need
two-way communication with servers that does not rely on opening
multiple {HTTP} connections (e.g., using {XMLHttpRequest} or
 s and long polling). [{STANDARDS}-{TRACK}]},
	journaltitle = {{RFC}},
	author = {Fette, Ian and Melnikov, A.},
	date = {2011},
	file = {Full Text:C\:\\Users\\vimio\\Zotero\\storage\\HVA5ZU7Q\\Fette and Melnikov - 2011 - The WebSocket Protocol.pdf:application/pdf},
}

@inproceedings{azzopardi_towards_2011,
	location = {Berlin, Heidelberg},
	title = {Towards a Living Lab for Information Retrieval Research and Development},
	isbn = {978-3-642-23708-9},
	doi = {10.1007/978-3-642-23708-9_5},
	series = {Lecture Notes in Computer Science},
	abstract = {The notion of having a “living lab” to undertaken evaluations has been proposed by a number of proponents within the field of Information Retrieval ({IR}). However, what such a living lab might look like and how it might be setup has not been discussed in detail. Living labs have a number of appealing points such as realistic evaluation contexts where tasks are directly linked to user experience and the closer integration of research/academia and development/industry facilitating more efficient knowledge transfer. However, operationalizing a living lab opens up a number of concerns regarding security, privacy, etc. as well as challenges regarding the design, development and maintenance of the infrastructure required to support such evaluations. Here, we aim to further the discussion on living labs for {IR} evaluation and propose one possible architecture to create such an evaluation environment. To focus discussion, we put forward a proposal for a living lab on product search tasks within the context of an online shop.},
	pages = {26--37},
	booktitle = {Multilingual and Multimodal Information Access Evaluation},
	publisher = {Springer},
	author = {Azzopardi, Leif and Balog, Krisztian},
	editor = {Forner, Pamela and Gonzalo, Julio and Kekäläinen, Jaana and Lalmas, Mounia and de Rijke, Marteen},
	date = {2011},
	langid = {english},
	keywords = {Commercial Organization, Online Shop, Product Search, Query Suggestion, Test Collection},
}